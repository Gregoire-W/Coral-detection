{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, distutils.core\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2024 NVIDIA Corporation\n",
      "Built on Thu_Mar_28_02:18:24_PDT_2024\n",
      "Cuda compilation tools, release 12.4, V12.4.131\n",
      "Build cuda_12.4.r12.4/compiler.34097967_0\n",
      "torch:  2.5 ; cuda:  cu124\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n",
    "im = cv2.imread(\"./input.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/12 15:20:07 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_f10217.pkl: 178MB [00:05, 34.9MB/s]                            \n",
      "/opt/conda/lib/python3.12/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "cfg = get_cfg()\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "outputs = predictor(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([17,  0,  0,  0,  0,  0,  0,  0, 25,  0, 25, 25,  0,  0, 24],\n",
      "       device='cuda:0')\n",
      "Boxes(tensor([[126.5985, 244.9039, 459.8283, 480.0000],\n",
      "        [251.1051, 157.8163, 338.9748, 413.6253],\n",
      "        [114.8519, 268.6908, 148.2369, 398.8166],\n",
      "        [  0.8215, 281.0366,  78.6025, 478.4248],\n",
      "        [ 49.3943, 274.1233,  80.1552, 342.9868],\n",
      "        [561.2267, 271.5826, 596.2765, 385.2516],\n",
      "        [385.9061, 270.3122, 413.7124, 304.0400],\n",
      "        [515.9238, 278.3691, 562.2795, 389.3792],\n",
      "        [335.2389, 251.9167, 414.7491, 275.9345],\n",
      "        [350.9279, 269.2094, 386.0966, 297.9086],\n",
      "        [331.6266, 231.0002, 393.2768, 257.2017],\n",
      "        [510.7307, 263.2701, 570.9870, 295.9414],\n",
      "        [409.0865, 271.8633, 460.5579, 356.8701],\n",
      "        [506.8876, 283.3300, 529.9465, 324.0268],\n",
      "        [594.5670, 283.4811, 609.0570, 311.4140]], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "# look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification\n",
    "print(outputs[\"instances\"].pred_classes)\n",
    "print(outputs[\"instances\"].pred_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use `Visualizer` to draw the predictions on the image.\n",
    "v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2.imwrite(\"output.jpg\", out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"my_dataset_train\", {}, \"./detectron_datasets/1/train/_annotations.coco.json\", \"./detectron_datasets/1/train\")\n",
    "register_coco_instances(\"my_dataset_val\", {}, \"./detectron_datasets/1/valid/_annotations.coco.json\", \"./detectron_datasets/1/valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = [\"coral\", \"Acanthastrea\", \"Acropora\", \"Coeloseris mayeri\", \"Diploastrea\", \"Favia\", \"Fungia\", \"Goniastrea\",\n",
    " \"Goniopora\", \"Isopora\", \"Leptastrea\", \"Lobophyllia\", \"Montipora\", \"Pavona\", \"Platygyra\", \"Pocillopora\", \"Porites\", \"Sarcophyton\", \"Stylophora pistillata\", \"Turbinaria\"]\n",
    "len(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetadataCatalog.get(\"my_dataset_train\").thing_classes = class_labels\n",
    "corals_metadata = MetadataCatalog.get(\"my_dataset_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/12 15:49:00 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/12 15:49:00 d2.data.datasets.coco]: \u001b[0mLoaded 194 images in COCO format from ./detectron_datasets/1/train/_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\n",
    "for i, d in enumerate(random.sample(dataset_dicts, 3)):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=corals_metadata, scale=0.5)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    cv2.imwrite(f\"corals{i}.jpg\", out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/12 15:52:20 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=20, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=76, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/12 15:52:20 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/12 15:52:20 d2.data.datasets.coco]: \u001b[0mLoaded 194 images in COCO format from ./detectron_datasets/1/train/_annotations.coco.json\n",
      "\u001b[32m[12/12 15:52:20 d2.data.build]: \u001b[0mRemoved 5 images with no usable annotations. 189 images left.\n",
      "\u001b[32m[12/12 15:52:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[12/12 15:52:20 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[12/12 15:52:20 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[12/12 15:52:20 d2.data.common]: \u001b[0mSerializing 189 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[12/12 15:52:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.07 MiB\n",
      "\u001b[32m[12/12 15:52:20 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
      "\u001b[32m[12/12 15:52:20 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_280758.pkl: 167MB [00:01, 101MB/s]                             \n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (20, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (76, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (76,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/12 15:52:22 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[12/12 15:52:35 d2.utils.events]: \u001b[0m eta: 0:18:58  iter: 19  total_loss: 3.452  loss_cls: 2.958  loss_box_reg: 0.235  loss_rpn_cls: 0.2143  loss_rpn_loc: 0.03134    time: 0.5796  last_time: 0.5423  data_time: 0.0481  last_data_time: 0.0082   lr: 4.9953e-06  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:52:46 d2.utils.events]: \u001b[0m eta: 0:18:07  iter: 39  total_loss: 3.151  loss_cls: 2.749  loss_box_reg: 0.1525  loss_rpn_cls: 0.2195  loss_rpn_loc: 0.03151    time: 0.5632  last_time: 0.4512  data_time: 0.0079  last_data_time: 0.0091   lr: 9.9902e-06  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:52:57 d2.utils.events]: \u001b[0m eta: 0:18:06  iter: 59  total_loss: 2.557  loss_cls: 2.269  loss_box_reg: 0.2036  loss_rpn_cls: 0.08523  loss_rpn_loc: 0.02542    time: 0.5606  last_time: 0.6051  data_time: 0.0062  last_data_time: 0.0049   lr: 1.4985e-05  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:53:08 d2.utils.events]: \u001b[0m eta: 0:17:26  iter: 79  total_loss: 1.926  loss_cls: 1.554  loss_box_reg: 0.196  loss_rpn_cls: 0.1246  loss_rpn_loc: 0.02331    time: 0.5527  last_time: 0.5309  data_time: 0.0074  last_data_time: 0.0095   lr: 1.998e-05  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:53:19 d2.utils.events]: \u001b[0m eta: 0:17:12  iter: 99  total_loss: 1.182  loss_cls: 0.7108  loss_box_reg: 0.2246  loss_rpn_cls: 0.1429  loss_rpn_loc: 0.03054    time: 0.5511  last_time: 0.4503  data_time: 0.0077  last_data_time: 0.0074   lr: 2.4975e-05  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:53:29 d2.utils.events]: \u001b[0m eta: 0:17:03  iter: 119  total_loss: 0.7349  loss_cls: 0.4194  loss_box_reg: 0.1837  loss_rpn_cls: 0.1156  loss_rpn_loc: 0.02667    time: 0.5504  last_time: 0.5454  data_time: 0.0071  last_data_time: 0.0060   lr: 2.997e-05  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:53:40 d2.utils.events]: \u001b[0m eta: 0:16:50  iter: 139  total_loss: 0.7441  loss_cls: 0.3757  loss_box_reg: 0.1901  loss_rpn_cls: 0.1322  loss_rpn_loc: 0.03194    time: 0.5499  last_time: 0.5375  data_time: 0.0069  last_data_time: 0.0084   lr: 3.4965e-05  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:53:52 d2.utils.events]: \u001b[0m eta: 0:16:43  iter: 159  total_loss: 0.8068  loss_cls: 0.4535  loss_box_reg: 0.2528  loss_rpn_cls: 0.0742  loss_rpn_loc: 0.02599    time: 0.5508  last_time: 0.5670  data_time: 0.0074  last_data_time: 0.0065   lr: 3.996e-05  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:54:03 d2.utils.events]: \u001b[0m eta: 0:16:32  iter: 179  total_loss: 0.7962  loss_cls: 0.424  loss_box_reg: 0.2383  loss_rpn_cls: 0.06809  loss_rpn_loc: 0.02209    time: 0.5512  last_time: 0.5978  data_time: 0.0078  last_data_time: 0.0090   lr: 4.4955e-05  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:54:14 d2.utils.events]: \u001b[0m eta: 0:16:21  iter: 199  total_loss: 0.7845  loss_cls: 0.4191  loss_box_reg: 0.2274  loss_rpn_cls: 0.067  loss_rpn_loc: 0.02904    time: 0.5512  last_time: 0.4478  data_time: 0.0090  last_data_time: 0.0065   lr: 4.995e-05  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:54:24 d2.utils.events]: \u001b[0m eta: 0:16:05  iter: 219  total_loss: 0.6427  loss_cls: 0.3419  loss_box_reg: 0.1975  loss_rpn_cls: 0.08304  loss_rpn_loc: 0.02289    time: 0.5494  last_time: 0.5699  data_time: 0.0074  last_data_time: 0.0042   lr: 5.4945e-05  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:54:35 d2.utils.events]: \u001b[0m eta: 0:15:50  iter: 239  total_loss: 0.7542  loss_cls: 0.4034  loss_box_reg: 0.2319  loss_rpn_cls: 0.07267  loss_rpn_loc: 0.02228    time: 0.5485  last_time: 0.5947  data_time: 0.0073  last_data_time: 0.0057   lr: 5.994e-05  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:54:46 d2.utils.events]: \u001b[0m eta: 0:15:37  iter: 259  total_loss: 0.7136  loss_cls: 0.3997  loss_box_reg: 0.2509  loss_rpn_cls: 0.06508  loss_rpn_loc: 0.0227    time: 0.5471  last_time: 0.5135  data_time: 0.0074  last_data_time: 0.0046   lr: 6.4935e-05  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:54:57 d2.utils.events]: \u001b[0m eta: 0:15:26  iter: 279  total_loss: 0.7367  loss_cls: 0.406  loss_box_reg: 0.2455  loss_rpn_cls: 0.05245  loss_rpn_loc: 0.02388    time: 0.5464  last_time: 0.4303  data_time: 0.0069  last_data_time: 0.0044   lr: 6.993e-05  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:55:07 d2.utils.events]: \u001b[0m eta: 0:15:15  iter: 299  total_loss: 0.7819  loss_cls: 0.4258  loss_box_reg: 0.2881  loss_rpn_cls: 0.05691  loss_rpn_loc: 0.02265    time: 0.5460  last_time: 0.4995  data_time: 0.0075  last_data_time: 0.0059   lr: 7.4925e-05  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:55:19 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 319  total_loss: 0.7502  loss_cls: 0.387  loss_box_reg: 0.2712  loss_rpn_cls: 0.03508  loss_rpn_loc: 0.02204    time: 0.5468  last_time: 0.5512  data_time: 0.0077  last_data_time: 0.0079   lr: 7.992e-05  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:55:29 d2.utils.events]: \u001b[0m eta: 0:14:52  iter: 339  total_loss: 0.7303  loss_cls: 0.3995  loss_box_reg: 0.2714  loss_rpn_cls: 0.04631  loss_rpn_loc: 0.02494    time: 0.5451  last_time: 0.5267  data_time: 0.0077  last_data_time: 0.0053   lr: 8.4915e-05  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:55:40 d2.utils.events]: \u001b[0m eta: 0:14:41  iter: 359  total_loss: 0.8736  loss_cls: 0.4725  loss_box_reg: 0.328  loss_rpn_cls: 0.04958  loss_rpn_loc: 0.02263    time: 0.5445  last_time: 0.4352  data_time: 0.0078  last_data_time: 0.0091   lr: 8.991e-05  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:55:51 d2.utils.events]: \u001b[0m eta: 0:14:32  iter: 379  total_loss: 0.8194  loss_cls: 0.4168  loss_box_reg: 0.3309  loss_rpn_cls: 0.0485  loss_rpn_loc: 0.02695    time: 0.5455  last_time: 0.5449  data_time: 0.0072  last_data_time: 0.0053   lr: 9.4905e-05  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:56:02 d2.utils.events]: \u001b[0m eta: 0:14:20  iter: 399  total_loss: 0.7073  loss_cls: 0.3597  loss_box_reg: 0.288  loss_rpn_cls: 0.04798  loss_rpn_loc: 0.02112    time: 0.5447  last_time: 0.5346  data_time: 0.0079  last_data_time: 0.0064   lr: 9.99e-05  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:56:13 d2.utils.events]: \u001b[0m eta: 0:14:09  iter: 419  total_loss: 0.8124  loss_cls: 0.4158  loss_box_reg: 0.3176  loss_rpn_cls: 0.02936  loss_rpn_loc: 0.01916    time: 0.5446  last_time: 0.5664  data_time: 0.0081  last_data_time: 0.0087   lr: 0.0001049  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:56:23 d2.utils.events]: \u001b[0m eta: 0:13:58  iter: 439  total_loss: 0.8084  loss_cls: 0.3882  loss_box_reg: 0.3035  loss_rpn_cls: 0.05148  loss_rpn_loc: 0.02356    time: 0.5436  last_time: 0.5195  data_time: 0.0083  last_data_time: 0.0081   lr: 0.00010989  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:56:34 d2.utils.events]: \u001b[0m eta: 0:13:46  iter: 459  total_loss: 0.7973  loss_cls: 0.4011  loss_box_reg: 0.3236  loss_rpn_cls: 0.03701  loss_rpn_loc: 0.01707    time: 0.5434  last_time: 0.5207  data_time: 0.0083  last_data_time: 0.0060   lr: 0.00011489  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:56:44 d2.utils.events]: \u001b[0m eta: 0:13:35  iter: 479  total_loss: 0.7945  loss_cls: 0.4051  loss_box_reg: 0.3468  loss_rpn_cls: 0.03562  loss_rpn_loc: 0.01783    time: 0.5426  last_time: 0.5807  data_time: 0.0072  last_data_time: 0.0073   lr: 0.00011988  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:56:55 d2.utils.events]: \u001b[0m eta: 0:13:24  iter: 499  total_loss: 0.8073  loss_cls: 0.3844  loss_box_reg: 0.3208  loss_rpn_cls: 0.03644  loss_rpn_loc: 0.02156    time: 0.5422  last_time: 0.5413  data_time: 0.0079  last_data_time: 0.0056   lr: 0.00012488  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:57:06 d2.utils.events]: \u001b[0m eta: 0:13:13  iter: 519  total_loss: 0.8707  loss_cls: 0.4452  loss_box_reg: 0.3585  loss_rpn_cls: 0.04163  loss_rpn_loc: 0.02329    time: 0.5415  last_time: 0.5766  data_time: 0.0074  last_data_time: 0.0091   lr: 0.00012987  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:57:16 d2.utils.events]: \u001b[0m eta: 0:13:02  iter: 539  total_loss: 0.8553  loss_cls: 0.4036  loss_box_reg: 0.3371  loss_rpn_cls: 0.03579  loss_rpn_loc: 0.02335    time: 0.5414  last_time: 0.6022  data_time: 0.0080  last_data_time: 0.0062   lr: 0.00013487  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:57:28 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 559  total_loss: 0.8134  loss_cls: 0.3816  loss_box_reg: 0.3736  loss_rpn_cls: 0.01924  loss_rpn_loc: 0.01771    time: 0.5419  last_time: 0.6352  data_time: 0.0074  last_data_time: 0.0070   lr: 0.00013986  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:57:38 d2.utils.events]: \u001b[0m eta: 0:12:41  iter: 579  total_loss: 0.7835  loss_cls: 0.3907  loss_box_reg: 0.3061  loss_rpn_cls: 0.0317  loss_rpn_loc: 0.02022    time: 0.5413  last_time: 0.4551  data_time: 0.0064  last_data_time: 0.0060   lr: 0.00014486  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:57:49 d2.utils.events]: \u001b[0m eta: 0:12:31  iter: 599  total_loss: 0.8648  loss_cls: 0.3915  loss_box_reg: 0.3706  loss_rpn_cls: 0.03393  loss_rpn_loc: 0.02299    time: 0.5419  last_time: 0.5926  data_time: 0.0075  last_data_time: 0.0064   lr: 0.00014985  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:58:00 d2.utils.events]: \u001b[0m eta: 0:12:20  iter: 619  total_loss: 0.716  loss_cls: 0.3378  loss_box_reg: 0.3078  loss_rpn_cls: 0.03271  loss_rpn_loc: 0.0207    time: 0.5419  last_time: 0.5676  data_time: 0.0081  last_data_time: 0.0063   lr: 0.00015485  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:58:11 d2.utils.events]: \u001b[0m eta: 0:12:09  iter: 639  total_loss: 0.774  loss_cls: 0.4008  loss_box_reg: 0.3813  loss_rpn_cls: 0.02885  loss_rpn_loc: 0.01914    time: 0.5416  last_time: 0.5590  data_time: 0.0082  last_data_time: 0.0065   lr: 0.00015984  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:58:22 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 659  total_loss: 0.7506  loss_cls: 0.3835  loss_box_reg: 0.3377  loss_rpn_cls: 0.02514  loss_rpn_loc: 0.01623    time: 0.5418  last_time: 0.5280  data_time: 0.0081  last_data_time: 0.0066   lr: 0.00016484  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:58:33 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 679  total_loss: 0.7792  loss_cls: 0.3726  loss_box_reg: 0.3361  loss_rpn_cls: 0.0244  loss_rpn_loc: 0.01645    time: 0.5414  last_time: 0.5711  data_time: 0.0079  last_data_time: 0.0075   lr: 0.00016983  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:58:44 d2.utils.events]: \u001b[0m eta: 0:11:37  iter: 699  total_loss: 0.726  loss_cls: 0.3484  loss_box_reg: 0.3157  loss_rpn_cls: 0.02627  loss_rpn_loc: 0.01939    time: 0.5416  last_time: 0.4390  data_time: 0.0084  last_data_time: 0.0080   lr: 0.00017483  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:58:55 d2.utils.events]: \u001b[0m eta: 0:11:26  iter: 719  total_loss: 0.702  loss_cls: 0.3538  loss_box_reg: 0.2949  loss_rpn_cls: 0.02908  loss_rpn_loc: 0.01982    time: 0.5414  last_time: 0.6266  data_time: 0.0082  last_data_time: 0.0079   lr: 0.00017982  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:59:06 d2.utils.events]: \u001b[0m eta: 0:11:16  iter: 739  total_loss: 0.7845  loss_cls: 0.3775  loss_box_reg: 0.3353  loss_rpn_cls: 0.03284  loss_rpn_loc: 0.02039    time: 0.5417  last_time: 0.5663  data_time: 0.0079  last_data_time: 0.0059   lr: 0.00018482  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:59:16 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 759  total_loss: 0.7252  loss_cls: 0.3555  loss_box_reg: 0.3005  loss_rpn_cls: 0.01762  loss_rpn_loc: 0.01569    time: 0.5414  last_time: 0.5885  data_time: 0.0082  last_data_time: 0.0079   lr: 0.00018981  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:59:27 d2.utils.events]: \u001b[0m eta: 0:10:54  iter: 779  total_loss: 0.6669  loss_cls: 0.3364  loss_box_reg: 0.2842  loss_rpn_cls: 0.02817  loss_rpn_loc: 0.01981    time: 0.5409  last_time: 0.5755  data_time: 0.0102  last_data_time: 0.0060   lr: 0.00019481  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:59:38 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 799  total_loss: 0.5877  loss_cls: 0.2973  loss_box_reg: 0.2441  loss_rpn_cls: 0.01731  loss_rpn_loc: 0.01844    time: 0.5410  last_time: 0.5802  data_time: 0.0075  last_data_time: 0.0074   lr: 0.0001998  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:59:49 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 819  total_loss: 0.7471  loss_cls: 0.3887  loss_box_reg: 0.32  loss_rpn_cls: 0.02067  loss_rpn_loc: 0.01626    time: 0.5412  last_time: 0.5754  data_time: 0.0077  last_data_time: 0.0091   lr: 0.0002048  max_mem: 3472M\n",
      "\u001b[32m[12/12 15:59:59 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 839  total_loss: 0.7231  loss_cls: 0.3635  loss_box_reg: 0.3021  loss_rpn_cls: 0.02318  loss_rpn_loc: 0.0162    time: 0.5409  last_time: 0.4591  data_time: 0.0074  last_data_time: 0.0050   lr: 0.00020979  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:00:10 d2.utils.events]: \u001b[0m eta: 0:10:10  iter: 859  total_loss: 0.6696  loss_cls: 0.346  loss_box_reg: 0.2946  loss_rpn_cls: 0.01875  loss_rpn_loc: 0.01965    time: 0.5408  last_time: 0.5360  data_time: 0.0076  last_data_time: 0.0081   lr: 0.00021479  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:00:21 d2.utils.events]: \u001b[0m eta: 0:09:59  iter: 879  total_loss: 0.5595  loss_cls: 0.2796  loss_box_reg: 0.2362  loss_rpn_cls: 0.01519  loss_rpn_loc: 0.0146    time: 0.5404  last_time: 0.5223  data_time: 0.0074  last_data_time: 0.0075   lr: 0.00021978  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:00:31 d2.utils.events]: \u001b[0m eta: 0:09:48  iter: 899  total_loss: 0.7099  loss_cls: 0.35  loss_box_reg: 0.3225  loss_rpn_cls: 0.02249  loss_rpn_loc: 0.01836    time: 0.5401  last_time: 0.4485  data_time: 0.0080  last_data_time: 0.0102   lr: 0.00022478  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:00:42 d2.utils.events]: \u001b[0m eta: 0:09:37  iter: 919  total_loss: 0.631  loss_cls: 0.3483  loss_box_reg: 0.26  loss_rpn_cls: 0.02035  loss_rpn_loc: 0.01908    time: 0.5400  last_time: 0.5262  data_time: 0.0078  last_data_time: 0.0068   lr: 0.00022977  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:00:53 d2.utils.events]: \u001b[0m eta: 0:09:26  iter: 939  total_loss: 0.6323  loss_cls: 0.3422  loss_box_reg: 0.2778  loss_rpn_cls: 0.02369  loss_rpn_loc: 0.01757    time: 0.5401  last_time: 0.5688  data_time: 0.0071  last_data_time: 0.0059   lr: 0.00023477  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:01:03 d2.utils.events]: \u001b[0m eta: 0:09:16  iter: 959  total_loss: 0.6429  loss_cls: 0.3164  loss_box_reg: 0.2815  loss_rpn_cls: 0.01301  loss_rpn_loc: 0.01782    time: 0.5396  last_time: 0.5377  data_time: 0.0076  last_data_time: 0.0065   lr: 0.00023976  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:01:14 d2.utils.events]: \u001b[0m eta: 0:09:05  iter: 979  total_loss: 0.614  loss_cls: 0.3192  loss_box_reg: 0.2358  loss_rpn_cls: 0.01425  loss_rpn_loc: 0.01714    time: 0.5392  last_time: 0.5286  data_time: 0.0084  last_data_time: 0.0087   lr: 0.00024476  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:01:24 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 999  total_loss: 0.5967  loss_cls: 0.297  loss_box_reg: 0.2668  loss_rpn_cls: 0.01711  loss_rpn_loc: 0.01585    time: 0.5389  last_time: 0.5768  data_time: 0.0069  last_data_time: 0.0077   lr: 0.00024975  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:01:35 d2.utils.events]: \u001b[0m eta: 0:08:43  iter: 1019  total_loss: 0.7244  loss_cls: 0.3884  loss_box_reg: 0.3054  loss_rpn_cls: 0.01675  loss_rpn_loc: 0.01711    time: 0.5388  last_time: 0.6255  data_time: 0.0076  last_data_time: 0.0059   lr: 0.00025  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:01:46 d2.utils.events]: \u001b[0m eta: 0:08:32  iter: 1039  total_loss: 0.5597  loss_cls: 0.277  loss_box_reg: 0.244  loss_rpn_cls: 0.01878  loss_rpn_loc: 0.01883    time: 0.5391  last_time: 0.5739  data_time: 0.0080  last_data_time: 0.0070   lr: 0.00025  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:01:57 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 1059  total_loss: 0.6268  loss_cls: 0.3391  loss_box_reg: 0.2686  loss_rpn_cls: 0.01586  loss_rpn_loc: 0.02196    time: 0.5391  last_time: 0.5609  data_time: 0.0079  last_data_time: 0.0076   lr: 0.00025  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:02:07 d2.utils.events]: \u001b[0m eta: 0:08:10  iter: 1079  total_loss: 0.6153  loss_cls: 0.3208  loss_box_reg: 0.265  loss_rpn_cls: 0.01519  loss_rpn_loc: 0.01508    time: 0.5385  last_time: 0.5090  data_time: 0.0061  last_data_time: 0.0095   lr: 0.00025  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:02:18 d2.utils.events]: \u001b[0m eta: 0:07:59  iter: 1099  total_loss: 0.5674  loss_cls: 0.2864  loss_box_reg: 0.2426  loss_rpn_cls: 0.01645  loss_rpn_loc: 0.01642    time: 0.5386  last_time: 0.6590  data_time: 0.0074  last_data_time: 0.0094   lr: 0.00025  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:02:29 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 1119  total_loss: 0.5065  loss_cls: 0.2496  loss_box_reg: 0.2315  loss_rpn_cls: 0.01041  loss_rpn_loc: 0.01448    time: 0.5387  last_time: 0.5010  data_time: 0.0075  last_data_time: 0.0068   lr: 0.00025  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:02:39 d2.utils.events]: \u001b[0m eta: 0:07:37  iter: 1139  total_loss: 0.704  loss_cls: 0.3658  loss_box_reg: 0.2874  loss_rpn_cls: 0.01905  loss_rpn_loc: 0.01879    time: 0.5385  last_time: 0.4505  data_time: 0.0074  last_data_time: 0.0084   lr: 0.00025  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:02:51 d2.utils.events]: \u001b[0m eta: 0:07:26  iter: 1159  total_loss: 0.5587  loss_cls: 0.2743  loss_box_reg: 0.275  loss_rpn_cls: 0.01465  loss_rpn_loc: 0.01499    time: 0.5387  last_time: 0.6248  data_time: 0.0076  last_data_time: 0.0097   lr: 0.00025  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:03:02 d2.utils.events]: \u001b[0m eta: 0:07:16  iter: 1179  total_loss: 0.6198  loss_cls: 0.3263  loss_box_reg: 0.2722  loss_rpn_cls: 0.02003  loss_rpn_loc: 0.01829    time: 0.5390  last_time: 0.5740  data_time: 0.0084  last_data_time: 0.0084   lr: 0.00025  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:03:13 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 1199  total_loss: 0.6344  loss_cls: 0.3427  loss_box_reg: 0.2518  loss_rpn_cls: 0.01516  loss_rpn_loc: 0.0185    time: 0.5389  last_time: 0.6434  data_time: 0.0086  last_data_time: 0.0075   lr: 0.00025  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:03:24 d2.utils.events]: \u001b[0m eta: 0:06:54  iter: 1219  total_loss: 0.5294  loss_cls: 0.2616  loss_box_reg: 0.2315  loss_rpn_cls: 0.01198  loss_rpn_loc: 0.01641    time: 0.5390  last_time: 0.5698  data_time: 0.0081  last_data_time: 0.0091   lr: 0.00025  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:03:35 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 1239  total_loss: 0.5888  loss_cls: 0.2907  loss_box_reg: 0.2666  loss_rpn_cls: 0.01414  loss_rpn_loc: 0.01539    time: 0.5391  last_time: 0.5353  data_time: 0.0081  last_data_time: 0.0095   lr: 0.00025  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:03:45 d2.utils.events]: \u001b[0m eta: 0:06:32  iter: 1259  total_loss: 0.5556  loss_cls: 0.2883  loss_box_reg: 0.2473  loss_rpn_cls: 0.01053  loss_rpn_loc: 0.01762    time: 0.5386  last_time: 0.4571  data_time: 0.0075  last_data_time: 0.0072   lr: 0.00025  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:03:55 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 1279  total_loss: 0.5263  loss_cls: 0.2614  loss_box_reg: 0.2446  loss_rpn_cls: 0.01334  loss_rpn_loc: 0.01615    time: 0.5384  last_time: 0.5639  data_time: 0.0074  last_data_time: 0.0073   lr: 0.00025  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:04:06 d2.utils.events]: \u001b[0m eta: 0:06:10  iter: 1299  total_loss: 0.6088  loss_cls: 0.3013  loss_box_reg: 0.2537  loss_rpn_cls: 0.01325  loss_rpn_loc: 0.01548    time: 0.5386  last_time: 0.5194  data_time: 0.0073  last_data_time: 0.0088   lr: 0.00025  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:04:17 d2.utils.events]: \u001b[0m eta: 0:05:59  iter: 1319  total_loss: 0.4893  loss_cls: 0.238  loss_box_reg: 0.2075  loss_rpn_cls: 0.0109  loss_rpn_loc: 0.015    time: 0.5386  last_time: 0.5133  data_time: 0.0079  last_data_time: 0.0063   lr: 0.00025  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:04:28 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 1339  total_loss: 0.5126  loss_cls: 0.2555  loss_box_reg: 0.2205  loss_rpn_cls: 0.007959  loss_rpn_loc: 0.01371    time: 0.5384  last_time: 0.5745  data_time: 0.0068  last_data_time: 0.0080   lr: 0.00025  max_mem: 3472M\n",
      "\u001b[32m[12/12 16:04:38 d2.utils.events]: \u001b[0m eta: 0:05:38  iter: 1359  total_loss: 0.62  loss_cls: 0.2993  loss_box_reg: 0.2541  loss_rpn_cls: 0.01156  loss_rpn_loc: 0.0173    time: 0.5382  last_time: 0.4937  data_time: 0.0069  last_data_time: 0.0077   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:04:49 d2.utils.events]: \u001b[0m eta: 0:05:27  iter: 1379  total_loss: 0.5271  loss_cls: 0.2523  loss_box_reg: 0.2313  loss_rpn_cls: 0.01199  loss_rpn_loc: 0.01463    time: 0.5380  last_time: 0.4680  data_time: 0.0073  last_data_time: 0.0081   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:05:00 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 1399  total_loss: 0.6609  loss_cls: 0.2884  loss_box_reg: 0.2768  loss_rpn_cls: 0.008371  loss_rpn_loc: 0.01849    time: 0.5380  last_time: 0.6014  data_time: 0.0085  last_data_time: 0.0073   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:05:10 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 1419  total_loss: 0.4495  loss_cls: 0.2104  loss_box_reg: 0.2169  loss_rpn_cls: 0.008777  loss_rpn_loc: 0.01535    time: 0.5379  last_time: 0.6396  data_time: 0.0076  last_data_time: 0.0083   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:05:21 d2.utils.events]: \u001b[0m eta: 0:04:55  iter: 1439  total_loss: 0.5852  loss_cls: 0.2793  loss_box_reg: 0.2671  loss_rpn_cls: 0.009749  loss_rpn_loc: 0.0151    time: 0.5376  last_time: 0.4955  data_time: 0.0078  last_data_time: 0.0125   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:05:31 d2.utils.events]: \u001b[0m eta: 0:04:44  iter: 1459  total_loss: 0.6152  loss_cls: 0.2837  loss_box_reg: 0.2662  loss_rpn_cls: 0.009617  loss_rpn_loc: 0.01776    time: 0.5374  last_time: 0.6173  data_time: 0.0091  last_data_time: 0.0061   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:05:42 d2.utils.events]: \u001b[0m eta: 0:04:34  iter: 1479  total_loss: 0.5105  loss_cls: 0.2388  loss_box_reg: 0.2457  loss_rpn_cls: 0.01242  loss_rpn_loc: 0.016    time: 0.5373  last_time: 0.6463  data_time: 0.0084  last_data_time: 0.0077   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:05:52 d2.utils.events]: \u001b[0m eta: 0:04:23  iter: 1499  total_loss: 0.4788  loss_cls: 0.2254  loss_box_reg: 0.2053  loss_rpn_cls: 0.006736  loss_rpn_loc: 0.01294    time: 0.5370  last_time: 0.5375  data_time: 0.0079  last_data_time: 0.0083   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:06:03 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 1519  total_loss: 0.5065  loss_cls: 0.211  loss_box_reg: 0.2414  loss_rpn_cls: 0.008876  loss_rpn_loc: 0.01658    time: 0.5370  last_time: 0.5290  data_time: 0.0080  last_data_time: 0.0066   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:06:13 d2.utils.events]: \u001b[0m eta: 0:04:02  iter: 1539  total_loss: 0.4262  loss_cls: 0.2036  loss_box_reg: 0.2101  loss_rpn_cls: 0.01063  loss_rpn_loc: 0.01393    time: 0.5369  last_time: 0.4934  data_time: 0.0085  last_data_time: 0.0077   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:06:24 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 1559  total_loss: 0.4137  loss_cls: 0.1858  loss_box_reg: 0.1978  loss_rpn_cls: 0.005153  loss_rpn_loc: 0.01311    time: 0.5368  last_time: 0.5726  data_time: 0.0078  last_data_time: 0.0067   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:06:34 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 1579  total_loss: 0.4877  loss_cls: 0.2359  loss_box_reg: 0.2298  loss_rpn_cls: 0.01017  loss_rpn_loc: 0.01406    time: 0.5365  last_time: 0.5071  data_time: 0.0082  last_data_time: 0.0104   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:06:45 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 1599  total_loss: 0.3863  loss_cls: 0.1789  loss_box_reg: 0.1922  loss_rpn_cls: 0.01177  loss_rpn_loc: 0.0156    time: 0.5366  last_time: 0.4624  data_time: 0.0072  last_data_time: 0.0093   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:06:56 d2.utils.events]: \u001b[0m eta: 0:03:20  iter: 1619  total_loss: 0.5111  loss_cls: 0.2392  loss_box_reg: 0.2278  loss_rpn_cls: 0.01187  loss_rpn_loc: 0.01597    time: 0.5367  last_time: 0.5694  data_time: 0.0078  last_data_time: 0.0080   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:07:07 d2.utils.events]: \u001b[0m eta: 0:03:09  iter: 1639  total_loss: 0.4325  loss_cls: 0.2057  loss_box_reg: 0.2352  loss_rpn_cls: 0.007738  loss_rpn_loc: 0.01627    time: 0.5365  last_time: 0.6178  data_time: 0.0079  last_data_time: 0.0072   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:07:17 d2.utils.events]: \u001b[0m eta: 0:02:58  iter: 1659  total_loss: 0.4357  loss_cls: 0.1844  loss_box_reg: 0.2155  loss_rpn_cls: 0.004413  loss_rpn_loc: 0.01548    time: 0.5364  last_time: 0.4403  data_time: 0.0077  last_data_time: 0.0104   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:07:28 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 1679  total_loss: 0.4204  loss_cls: 0.1992  loss_box_reg: 0.1974  loss_rpn_cls: 0.009448  loss_rpn_loc: 0.0142    time: 0.5362  last_time: 0.5641  data_time: 0.0074  last_data_time: 0.0084   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:07:39 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 1699  total_loss: 0.3667  loss_cls: 0.1685  loss_box_reg: 0.1697  loss_rpn_cls: 0.005475  loss_rpn_loc: 0.0145    time: 0.5363  last_time: 0.5357  data_time: 0.0076  last_data_time: 0.0086   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:07:49 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 1719  total_loss: 0.4947  loss_cls: 0.2064  loss_box_reg: 0.2565  loss_rpn_cls: 0.007255  loss_rpn_loc: 0.01509    time: 0.5363  last_time: 0.5634  data_time: 0.0076  last_data_time: 0.0061   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:08:00 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 1739  total_loss: 0.4116  loss_cls: 0.1803  loss_box_reg: 0.1789  loss_rpn_cls: 0.005325  loss_rpn_loc: 0.01191    time: 0.5361  last_time: 0.5284  data_time: 0.0084  last_data_time: 0.0084   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:08:11 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 1759  total_loss: 0.3738  loss_cls: 0.1535  loss_box_reg: 0.1992  loss_rpn_cls: 0.0049  loss_rpn_loc: 0.01386    time: 0.5363  last_time: 0.6347  data_time: 0.0095  last_data_time: 0.0073   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:08:22 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 1779  total_loss: 0.4467  loss_cls: 0.2151  loss_box_reg: 0.2142  loss_rpn_cls: 0.005084  loss_rpn_loc: 0.01279    time: 0.5363  last_time: 0.6114  data_time: 0.0077  last_data_time: 0.0081   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:08:33 d2.utils.events]: \u001b[0m eta: 0:01:45  iter: 1799  total_loss: 0.5751  loss_cls: 0.246  loss_box_reg: 0.2766  loss_rpn_cls: 0.006129  loss_rpn_loc: 0.01835    time: 0.5365  last_time: 0.5787  data_time: 0.0078  last_data_time: 0.0068   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:08:43 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 1819  total_loss: 0.4819  loss_cls: 0.1972  loss_box_reg: 0.2496  loss_rpn_cls: 0.006859  loss_rpn_loc: 0.01562    time: 0.5363  last_time: 0.5008  data_time: 0.0065  last_data_time: 0.0051   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:08:54 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 1839  total_loss: 0.4521  loss_cls: 0.1906  loss_box_reg: 0.2238  loss_rpn_cls: 0.003837  loss_rpn_loc: 0.01361    time: 0.5362  last_time: 0.4171  data_time: 0.0072  last_data_time: 0.0080   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:09:05 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 1859  total_loss: 0.4001  loss_cls: 0.1762  loss_box_reg: 0.2127  loss_rpn_cls: 0.007884  loss_rpn_loc: 0.01538    time: 0.5363  last_time: 0.5838  data_time: 0.0097  last_data_time: 0.0110   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:09:15 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 1879  total_loss: 0.4255  loss_cls: 0.2048  loss_box_reg: 0.2093  loss_rpn_cls: 0.007446  loss_rpn_loc: 0.0154    time: 0.5362  last_time: 0.5062  data_time: 0.0091  last_data_time: 0.0062   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:09:26 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 1899  total_loss: 0.329  loss_cls: 0.1348  loss_box_reg: 0.1817  loss_rpn_cls: 0.005668  loss_rpn_loc: 0.01422    time: 0.5360  last_time: 0.4090  data_time: 0.0076  last_data_time: 0.0068   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:09:36 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 1919  total_loss: 0.3464  loss_cls: 0.1553  loss_box_reg: 0.1854  loss_rpn_cls: 0.004349  loss_rpn_loc: 0.01287    time: 0.5360  last_time: 0.6464  data_time: 0.0073  last_data_time: 0.0056   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:09:47 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 1939  total_loss: 0.3567  loss_cls: 0.167  loss_box_reg: 0.1953  loss_rpn_cls: 0.006372  loss_rpn_loc: 0.01434    time: 0.5361  last_time: 0.5227  data_time: 0.0076  last_data_time: 0.0074   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:09:58 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 1959  total_loss: 0.4016  loss_cls: 0.1579  loss_box_reg: 0.2182  loss_rpn_cls: 0.007382  loss_rpn_loc: 0.01458    time: 0.5362  last_time: 0.5477  data_time: 0.0067  last_data_time: 0.0062   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:10:09 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 1979  total_loss: 0.3935  loss_cls: 0.1642  loss_box_reg: 0.2123  loss_rpn_cls: 0.003479  loss_rpn_loc: 0.01387    time: 0.5363  last_time: 0.4912  data_time: 0.0076  last_data_time: 0.0077   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:10:23 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1999  total_loss: 0.3826  loss_cls: 0.1539  loss_box_reg: 0.1999  loss_rpn_cls: 0.003734  loss_rpn_loc: 0.01019    time: 0.5363  last_time: 0.5353  data_time: 0.0082  last_data_time: 0.0088   lr: 0.00025  max_mem: 3473M\n",
      "\u001b[32m[12/12 16:10:23 d2.engine.hooks]: \u001b[0mOverall training speed: 1998 iterations in 0:17:51 (0.5363 s / it)\n",
      "\u001b[32m[12/12 16:10:23 d2.engine.hooks]: \u001b[0mTotal training time: 0:17:58 (0:00:06 on hooks)\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.OUTPUT_DIR = \"detectron_model\"\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 2000    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 19  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[12/12 16:17:17 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from detectron_model/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/12 16:14:28 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[12/12 16:14:28 d2.data.datasets.coco]: \u001b[0mLoaded 16 images in COCO format from ./detectron_datasets/1/valid/_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "DatasetCatalog.get(\"my_dataset_val\")\n",
    "for i, d in enumerate(random.sample(dataset_dicts, 3)):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=corals_metadata, \n",
    "                   scale=0.5, \n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2.imwrite(f\"predictions/detectron/val{i}.jpg\", out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "dir_path = \"./test_imgs\"\n",
    "for i, path in enumerate(random.sample(os.listdir(dir_path), 3)):    \n",
    "    im = cv2.imread(os.path.join(dir_path, path))\n",
    "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=corals_metadata, \n",
    "                   scale=0.5, \n",
    "    )\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2.imwrite(f\"predictions/detectron/{path}.jpg\", out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
